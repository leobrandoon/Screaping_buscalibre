{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping de Webs Est√°ticas\n",
    "\n",
    "Leonardo Gonzalez \n",
    "\n",
    "Contacto:leo.gonzalez11@gmail.com\n",
    "\n",
    "\n",
    "\"Cargando\" la pagina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos las librerias que vamos a utilizar para leer la pagina web\n",
    "import requests  # metodo que para leer html evitando errores de lectura, antes recuerda intalar\n",
    "import pprint    #esto nos premite imprimir cosas mas bonitas nada mas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traemos la pagina y la guardamos con el metodo get\n",
    "url = 'https://www.buscalibre.cl/libros/search?q=python'\n",
    "page= requests.get(url)\n",
    "#el metodo get su utiliza para leer datos existe otro metodos como el post y put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificamos que tipo de respuesta tenemos \n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos dos manera de leer una pagiana mediante el "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint.pprint(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos la libreria beautifulsoup4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ahora utilizaremos la libreria para extraer los datos html de la pagina que queremos.\n",
    "#con soup pordemos recorrer el html\n",
    "soup = BeautifulSoup(page.text, \"html\") #combierte el html en texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es posible ademas repasar el contenido de la pagina para mejorar la lectura y acceder a los niveles\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "#argumento parser ayuda a recorrer el html\n",
    "#https://code.tutsplus.com/es/tutorials/scraping-webpages-in-python-with-beautiful-soup-the-basics--cms-28211\n",
    "# soup=BeautifulSoup(page.content) tambien sirve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploramos los resultados\n",
    "results = soup.find_all('div',class_='producto')\n",
    "# table=soup.find_all('table')\n",
    "#buscamos todos los elementos que esten marcados con las clase producto \n",
    "print('articulos por pagina'+\" \"+str(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos visualizar de manera comoda lo que estamos haciendo con pprint\n",
    "\n",
    "#traemos los datos del elemento 0 para reviasr que este correcto\n",
    "print(results[0])\n",
    "\n",
    "# print(soup.prettify()) si queremos ver todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora queremos obtener una etiqueta dentro de un elemento de soup\n",
    "element = results[0]\n",
    "#creamos una var del titulo del libro\n",
    "book_title = element.find('a')['title'] #find devuelve el primer valor de un elemento\n",
    "print(book_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queremos obtener el precio \n",
    "element.find('div',class_='box-precio-v2').text #div solo pueden tener un atributo class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.find('div',class_='autor').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atributos custom \n",
    "print(element['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(element['data-precio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obteniendo data de un elemento anidado\n",
    "#todo los elemento se obtiene con find_all\n",
    "print(element.find_all('div', class_='descuento-v2')[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probamos un mensaje de error por que quremos recorrer todas las paginas posible hasta la ultima\n",
    "\n",
    "#buscamos un url que nos de erro\n",
    "URL = 'https://www.buscalibre.cl/libros/search?q=bailarina&page=100' #pagina 100\n",
    "response = requests.get(URL)\n",
    "not_found = 'Lo sentimos, pero no encontramos lo que buscas'\n",
    "print(response.status_code)\n",
    "print (not_found not in response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tenemos todo lo necesario por unir todo y crear nuestro df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos las variables que queremos segun nuestro repaso anterior\n",
    "titulo=[]\n",
    "autor=[]\n",
    "precio=[]\n",
    "descuento=[]\n",
    "#tenemos el mensaje de error para cada pagina a recorer\n",
    "not_found_msg = 'Lo sentimos, pero no encontramos lo que buscas'\n",
    "URL = 'https://www.buscalibre.cl/libros/search?q=python&page'\n",
    "pag_index = 1 #definimos en que pagina comenzamos la busqueda\n",
    "\n",
    "#utilizamos un bucle while para cumplir la condicion para \n",
    "while (True):\n",
    "    URL = 'https://www.buscalibre.cl/libros/search?q=python&page={0}'.format(pag_index) #recorrer las paginas\n",
    "    response = requests.get(URL)\n",
    "    #si el mensaje que definimos no aprece entonces\n",
    "    if (not_found_msg not in response.text):\n",
    "        #repasa el html\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        #busca todos los elementos que esten marcados con las clase producto \n",
    "        results = soup.find_all('div',class_='producto')\n",
    "        \n",
    "        #con el metodo for y append iteramos y rellenamos las listas\n",
    "        for element in results:\n",
    "            titulo.append(element.find('a')['title'])\n",
    "            autor.append(element.find('div',class_='autor').text)\n",
    "            precio.append(element['data-precio'])\n",
    "            descuento.append(element.find_all('div', class_='descuento-v2')[0].text)\n",
    "            pag_index+= 1\n",
    "    else:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para terminar importamos pandas para crear un df\n",
    "import pandas as pd\n",
    "\n",
    "#creamos el data con los encebezados que queramos\n",
    "data = {'titulo' : titulo, 'autor':autor, 'precio':precio, 'descuento':descuento}\n",
    "#creamos el df\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover el % de la columan dscto\n",
    "df['descuento'] = df['descuento'].apply(lambda x : x[:x.find('%dcto'):])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
